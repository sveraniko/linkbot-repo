from __future__ import annotations
from aiogram import Router, F
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton
from sqlalchemy.ext.asyncio import AsyncSession
from app.db import get_session
from app.config import settings
from app.services.memory import (
    get_active_project, get_chat_flags, get_context_filters_state, get_linked_project_ids,
    gather_context_sources, get_preferred_model, _ensure_user_state,
)
from app.models import BotMessage
from app.llm import ask_llm
from html import escape

router = Router()

# –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Ç–µ–≥–æ–≤
TAG_PROMPT_PREFIX = "–°–≤–æ–∏ —Ç–µ–≥–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)"

# Service texts that should be ignored by the chat handler
SERVICE_TEXTS = {"Ask ‚ùì", "‚öôÔ∏è Actions", "–ú–µ–Ω—é", "Menu", "–°—Ç–∞—Ç—É—Å", "Status"}

def answer_kb(msg_id: int, saved: bool):
    # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–Ω–æ–ø–∫–∏: Save / Summary / Tag / Delete / Refine
    return InlineKeyboardMarkup(inline_keyboard=[[
        InlineKeyboardButton(text=("‚úÖ Saved" if saved else "üíæ Save"), callback_data=f"ans:save:{msg_id}"),
        InlineKeyboardButton(text="üìå Summary", callback_data=f"ans:sum:{msg_id}"),
        InlineKeyboardButton(text="üè∑ Tag", callback_data=f"ans:tag:{msg_id}"),
    ],[
        InlineKeyboardButton(text="üóë Delete", callback_data=f"ans:del:{msg_id}"),
        InlineKeyboardButton(text="‚Ü© Refine", callback_data=f"ans:ref:{msg_id}"),
    ]])

@router.message(F.text & ~F.text.startswith("/"))
async def on_free_text(message: Message):
    from app.db import session_scope
    async with session_scope() as st:
        if not message.from_user:
            return
        
        # –ï—Å–ª–∏ —ç—Ç–æ –æ—Ç–≤–µ—Ç –Ω–∞ –Ω–∞—à —Ñ–æ—Ä—Å-–ø—Ä–æ–º–ø—Ç —Ç–µ–≥–æ–≤ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º,
        # –ø—É—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç tags_free_reply
        if message.reply_to_message and (
            (message.reply_to_message.text or "").startswith(TAG_PROMPT_PREFIX) or
            (message.reply_to_message.text or "").startswith("–°–≤–æ–∏ —Ç–µ–≥–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞")
        ):
            return

        # Ignore service texts
        text = (message.text or "").strip()
        if not text or text in SERVICE_TEXTS:
            return  # –Ω–µ —Ç—Ä–æ–≥–∞–µ–º

        stt = await _ensure_user_state(st, message.from_user.id)

        # 1) –µ—Å–ª–∏ –∂–¥—ë–º –≤–æ–ø—Ä–æ—Å –ø–æ—Å–ª–µ Ask (–∞—Ä–º–∏—Ä–æ–≤–∞–Ω)
        if stt.ask_armed:
            stt.ask_armed = False
            await st.commit()
            return await run_question_with_selection(message, st, stt, text)

        # Check if we're awaiting search input - if so, don't process with LLM (LLM safety) (Hotfix F)
        if stt.awaiting_ask_search:
            # Don't process with LLM when awaiting search input
            return

        chat_on, quiet_on, sources_mode, scope_mode = await get_chat_flags(st, message.from_user.id)
        if quiet_on:
            return
        if not chat_on:
            # –æ–¥–∏–Ω –º—è–≥–∫–∏–π —Ö–∏–Ω—Ç –º–æ–∂–Ω–æ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –≤ –ø–∞–º—è—Ç–∏, –Ω–æ –¥–ª—è MVP –ø—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—Ç–∏–º
            return await message.answer("üí° –í–∫–ª—é—á–∏ —á–∞—Ç: –Ω–∞–∂–º–∏ ¬´üí¨ Chat¬ª –Ω–∞ —Å–∏–Ω–µ–π –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—É /actions ‚Üí Quiet OFF.")
        
        proj = await get_active_project(st, message.from_user.id)
        if not proj:
            return await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –ø—Ä–æ–µ–∫—Ç: –æ—Ç–∫—Ä–æ–π Actions ‚Üí Projects (–∏–ª–∏ /project <name>).")
        
        # –°–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        ctx_texts = await gather_context_sources(
            st, message.from_user.id, proj.id,
            max_chunks=settings.project_max_chunks
        )

        model = await get_preferred_model(st, message.from_user.id)

        # –†–µ—à–∞–µ–º –ø–æ scope:
        prompt = message.text or ""
        final_ctx = ctx_texts if scope_mode in ("auto", "project") else []
        
        answer = await ask_llm(prompt, final_ctx, model=model)  # –≤–Ω—É—Ç—Ä–∏ ask_llm —Ç—ã —É–∂–µ —É–º–µ–µ—à—å —Å—à–∏–≤–∞—Ç—å ctx –≤ system

        # —à—Ç–∞–º–ø
        from app.services.memory import list_projects
        names = {p.id: p.name for p in await list_projects(st)}
        stamp = f"\n\n<i>Project: {escape(proj.name) if proj else '‚Äî'} ‚Ä¢ Scope: {scope_mode} ‚Ä¢ Sources: {sources_mode} ‚Ä¢ Model: {model}</i>"

        sent = await message.answer(answer + stamp)
        bm = BotMessage(
            chat_id=message.chat.id,
            user_id=message.from_user.id,
            tg_message_id=sent.message_id,
            reply_to_user_msg_id=message.message_id,
            artifact_id=None, saved=False,
            project_id=(proj.id if proj else None),
            used_projects={"ids": [proj.id] if proj else []},
        )
        st.add(bm); await st.commit()
        await sent.edit_reply_markup(reply_markup=answer_kb(sent.message_id, saved=False))

async def run_question_with_selection(message: Message, st: AsyncSession, stt, text: str):
    """Run question with selected artifacts only"""
    from app.services.artifacts import get_chunks_by_artifact_ids
    from app.services.memory import get_active_project, get_preferred_model, fetch_chunks_for_question
    from app.llm import ask_llm
    from app.models import BotMessage
    from html import escape
    
    proj = await get_active_project(st, message.from_user.id)
    if not proj:
        return await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –ø—Ä–æ–µ–∫—Ç: –æ—Ç–∫—Ä–æ–π Actions ‚Üí Projects (–∏–ª–∏ /project <name>).")
    
    model = await get_preferred_model(st, message.from_user.id)
    project_id = proj.id  # This is safe because we've already checked that proj is not None
    
    # Get chunks based on selection
    chunks, approx_tokens, has_selection, auto_clear = await fetch_chunks_for_question(
        st, message.from_user.id, project_id, model
    )
    
    answer = await ask_llm(text, chunks, model=model)
    
    # Clear selection if auto-clear is enabled
    if has_selection and auto_clear:
        stt.selected_artifact_ids = None
        await st.commit()
    
    # —à—Ç–∞–º–ø
    stamp = f"\n\n<i>Project: {escape(proj.name) if proj else '‚Äî'} ‚Ä¢ Scope: selected ‚Ä¢ Model: {model}</i>"
    
    sent = await message.answer(answer + stamp)
    bm = BotMessage(
        chat_id=message.chat.id,
        user_id=message.from_user.id,
        tg_message_id=sent.message_id,
        reply_to_user_msg_id=message.message_id,
        artifact_id=None, saved=False,
        project_id=project_id,
        used_projects={"ids": [project_id]},
    )
    st.add(bm); await st.commit()
    await sent.edit_reply_markup(reply_markup=answer_kb(sent.message_id, saved=False))
