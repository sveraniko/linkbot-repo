"""Handlers for ZIP file operations: import, generation, and comparison."""
from aiogram import Router, F
from aiogram.types import Message, BufferedInputFile
from aiogram.filters import Command
from sqlalchemy.ext.asyncio import AsyncSession
from app.config import settings
from app.db import get_session
from app.services.memory import get_active_project
from app.services.artifacts import create_import, get_or_create_project
from app.storage import save_file, load_file
from app.utils.zip_utils import (
    extract_text_files, make_zip, diff_archives, 
    validate_zip_file, get_file_stats
)
from app.llm import generate_zip_files, generate_single_file, analyze_diff_context
from app.services.memory import gather_context, list_artifacts
from app.tokenizer import make_chunks, count_tokens
import logging
import tempfile
from typing import List, Optional

logger = logging.getLogger(__name__)
router = Router()

@router.message(Command("importzip"))
async def import_zip_hint(message: Message):
    """Show help for importzip command."""
    await message.answer(
        "üì¶ –ò–º–ø–æ—Ä—Ç ZIP –∞—Ä—Ö–∏–≤–∞\\n\\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ ZIP —Ñ–∞–π–ª, –∑–∞—Ç–µ–º –æ—Ç–≤–µ—Ç—å—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π:\\n"
        "/importzip tags python,backend\\n\\n"
        "–ë–æ—Ç –∏–∑–≤–ª–µ—á–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (.py, .js, .md, .json, .sql –∏ –¥—Ä.) "
        "–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç –∏—Ö –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏."
    )

@router.message(Command("importzip"), F.reply_to_message)
async def import_zip_archive(message: Message, session: AsyncSession = get_session()):
    """Import ZIP archive and extract text files."""
    try:
        st = await anext(session)
        proj = await get_active_project(st, message.from_user.id)
        if not proj:
            await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç: /project <name>")
            return
            
        if not message.reply_to_message or not message.reply_to_message.document:
            await message.answer("–ù—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –∫–æ–º–∞–Ω–¥–æ–π /importzip –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å ZIP —Ñ–∞–π–ª–æ–º")
            return
            
        doc = message.reply_to_message.document
        
        # Check if it's a ZIP file
        if not doc.file_name or not doc.file_name.lower().endswith('.zip'):
            await message.answer("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ ZIP —Ñ–∞–π–ª—ã")
            return
            
        await message.answer("üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é ZIP –∞—Ä—Ö–∏–≤...")
        
        # Parse tags from command
        tags = []
        if message.text:
            parts = message.text.split("tags", 1)
            if len(parts) > 1:
                tags = [t.strip() for t in parts[1].split(',') if t.strip()]
        
        # Download ZIP file
        if not message.bot:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –±–æ—Ç—É")
            return
            
        file = await message.bot.get_file(doc.file_id)
        if not file.file_path:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
            return
            
        file_bytes_io = await message.bot.download_file(file.file_path)
        if not file_bytes_io:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª")
            return
            
        zip_data = file_bytes_io.read()
        
        # Validate ZIP file
        is_valid, error_msg = validate_zip_file(zip_data)
        if not is_valid:
            await message.answer(f"‚ùå {error_msg}")
            return
            
        # Get file statistics
        stats = get_file_stats(zip_data)
        
        # Save ZIP to MinIO as blob
        zip_uri = await save_file(doc.file_name, zip_data)
        
        # Create blob artifact for the ZIP file itself
        blob_tags = tags + ['zip', 'blob']
        await create_import(
            st, proj,
            title=f"ZIP Archive: {doc.file_name}",
            text=f"ZIP archive with {stats['total_files']} files. Text files: {stats['text_files']}, Binary files: {stats['binary_files']}",
            chunk_size=settings.chunk_size,
            overlap=settings.chunk_overlap,
            tags=blob_tags,
            uri=zip_uri
        )
        
        # Extract text files
        text_files = extract_text_files(zip_data)
        
        if not text_files:
            await message.answer("‚ö†Ô∏è –í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤")
            return
            
        # Process each text file as separate artifact
        processed_count = 0
        for file_path, content in text_files.items():
            try:
                # Determine tags for this file
                file_tags = tags.copy()
                file_ext = file_path.split('.')[-1].lower() if '.' in file_path else 'txt'
                if file_ext not in file_tags:
                    file_tags.append(file_ext)
                file_tags.append('extracted')
                
                # Create artifact for the file
                await create_import(
                    st, proj,
                    title=f"File: {file_path}",
                    text=content,
                    chunk_size=settings.chunk_size,
                    overlap=settings.chunk_overlap,
                    tags=file_tags,
                    uri=None  # File content is in raw_text
                )
                processed_count += 1
                
            except Exception as e:
                logger.error(f"Error processing file {file_path}: {e}")
                continue
                
        await st.commit()
        
        # Send summary
        tags_str = ', '.join(tags) if tags else '–Ω–µ—Ç'
        await message.answer(
            f"‚úÖ ZIP –∞—Ä—Ö–∏–≤ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ –ø—Ä–æ–µ–∫—Ç <b>{proj.name}</b>\\n\\n"
            f"üìÅ –ê—Ä—Ö–∏–≤: {doc.file_name}\\n"
            f"üìä –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} –∏–∑ {stats['text_files']} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö\\n"
            f"üè∑Ô∏è –¢–µ–≥–∏: {tags_str}\\n"
            f"üîó URI –∞—Ä—Ö–∏–≤–∞: {zip_uri or '‚Äî'}\\n\\n"
            f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\\n"
            f"  ‚Ä¢ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}\\n"
            f"  ‚Ä¢ –¢–µ–∫—Å—Ç–æ–≤—ã—Ö: {stats['text_files']}\\n"
            f"  ‚Ä¢ –ë–∏–Ω–∞—Ä–Ω—ã—Ö: {stats['binary_files']}"
        )
        
    except Exception as e:
        logger.error(f"Error importing ZIP: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ ZIP: {str(e)}")

@router.message(Command("genzip"))
async def generate_zip_archive(message: Message, session: AsyncSession = get_session()):
    """Generate ZIP archive using AI based on task description."""
    try:
        st = await anext(session)
        proj = await get_active_project(st, message.from_user.id)
        if not proj:
            await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç: /project <name>")
            return
            
        # Parse command: /genzip "description" tags tag1,tag2
        if not message.text:
            await message.answer("‚ùå –¢–µ–∫—Å—Ç –∫–æ–º–∞–Ω–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
            
        command_parts = message.text.split('"')
        if len(command_parts) < 3:
            await message.answer(
                "–§–æ—Ä–º–∞—Ç –∫–æ–º–∞–Ω–¥—ã:\\n"
                "/genzip \\"–æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏\\" tags python,backend\\n\\n"
                "–ü—Ä–∏–º–µ—Ä:\\n"
                "/genzip \\"–°–æ–∑–¥–∞—Ç—å API –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\\" tags api,users"
            )
            return
            
        task_description = command_parts[1].strip()
        
        # Parse tags
        tags = []
        remaining_text = command_parts[2] if len(command_parts) > 2 else ""
        if "tags" in remaining_text:
            tags_part = remaining_text.split("tags", 1)[1].strip()
            tags = [t.strip() for t in tags_part.split(',') if t.strip()]
            
        await message.answer("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞—Ä—Ö–∏–≤ —Ñ–∞–π–ª–æ–≤...")
        
        # Gather project context
        context_chunks = await gather_context(st, proj, user_id=message.from_user.id, max_chunks=settings.project_max_chunks)
        
        # Generate files using AI
        generated_files = await generate_zip_files(task_description, context_chunks, tags)
        
        if not generated_files:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã")
            return
            
        # Create ZIP archive
        zip_data = make_zip(generated_files)
        
        # Save ZIP to MinIO
        zip_filename = f"generated_{proj.name}_{len(generated_files)}_files.zip"
        zip_uri = await save_file(zip_filename, zip_data)
        
        # Create artifact for generated ZIP
        gen_tags = tags + ['generated', 'genzip']
        files_list = "\\n".join([f"  ‚Ä¢ {path}" for path in generated_files.keys()])
        
        await create_import(
            st, proj,
            title=f"Generated Archive: {task_description}",
            text=f"AI-generated archive for: {task_description}\\n\\nFiles:\\n{files_list}",
            chunk_size=settings.chunk_size,
            overlap=settings.chunk_overlap,
            tags=gen_tags,
            uri=zip_uri
        )
        
        await st.commit()
        
        # Send ZIP file as document
        zip_file = BufferedInputFile(zip_data, filename=zip_filename)
        
        tags_str = ', '.join(tags) if tags else '–Ω–µ—Ç'
        caption = (
            f"üéâ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞—Ä—Ö–∏–≤ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ <b>{proj.name}</b>\\n\\n"
            f"üìã –ó–∞–¥–∞—á–∞: {task_description}\\n"
            f"üìÅ –§–∞–π–ª–æ–≤: {len(generated_files)}\\n"
            f"üè∑Ô∏è –¢–µ–≥–∏: {tags_str}\\n"
            f"üîó URI: {zip_uri}\\n\\n"
            f"üìÑ –§–∞–π–ª—ã:\\n{files_list}"
        )
        
        await message.answer_document(zip_file, caption=caption)
        
    except Exception as e:
        logger.error(f"Error generating ZIP: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ZIP: {str(e)}")

@router.message(Command("genfile"))
async def generate_single_file_handler(message: Message, session: AsyncSession = get_session()):
    """Generate a single file using AI."""
    try:
        st = await anext(session)
        proj = await get_active_project(st, message.from_user.id)
        if not proj:
            await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç: /project <name>")
            return
            
        # Parse command: /genfile path=app/module/file.py "description"
        if not message.text:
            await message.answer("‚ùå –¢–µ–∫—Å—Ç –∫–æ–º–∞–Ω–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
            
        if "path=" not in message.text or '"' not in message.text:
            await message.answer(
                "–§–æ—Ä–º–∞—Ç –∫–æ–º–∞–Ω–¥—ã:\\n"
                "/genfile path=app/module/file.py \\"–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∞–≤–∫–∏\\"\\n\\n"
                "–ü—Ä–∏–º–µ—Ä:\\n"
                "/genfile path=src/auth/login.py \\"–î–æ–±–∞–≤–∏—Ç—å –¥–≤—É—Ö—Ñ–∞–∫—Ç–æ—Ä–Ω—É—é –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é\\""
            )
            return
            
        # Extract path
        path_part = message.text.split("path=")[1].split('"')[0].strip()
        file_path = path_part
        
        # Extract description
        desc_parts = message.text.split('"')
        if len(desc_parts) < 2:
            await message.answer("–£–∫–∞–∂–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –∫–∞–≤—ã—á–∫–∞—Ö")
            return
            
        task_description = desc_parts[1].strip()
        
        await message.answer(f"ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ñ–∞–π–ª {file_path}...")
        
        # Gather project context
        context_chunks = await gather_context(st, proj, user_id=message.from_user.id, max_chunks=settings.project_max_chunks)
        
        # Generate file content using AI
        file_content = await generate_single_file(file_path, task_description, context_chunks)
        
        # Save file to MinIO
        file_uri = await save_file(file_path.split('/')[-1], file_content.encode('utf-8'))
        
        # Create artifact for generated file
        file_ext = file_path.split('.')[-1].lower() if '.' in file_path else 'txt'
        gen_tags = [file_ext, 'generated', 'genfile']
        
        await create_import(
            st, proj,
            title=f"Generated File: {file_path}",
            text=file_content,
            chunk_size=settings.chunk_size,
            overlap=settings.chunk_overlap,
            tags=gen_tags,
            uri=file_uri
        )
        
        await st.commit()
        
        # Send file as document
        file_doc = BufferedInputFile(
            file_content.encode('utf-8'), 
            filename=file_path.split('/')[-1]
        )
        
        caption = (
            f"üìù –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ <b>{proj.name}</b>\\n\\n"
            f"üìÅ –ü—É—Ç—å: {file_path}\\n"
            f"üìã –ó–∞–¥–∞—á–∞: {task_description}\\n"
            f"üìä –†–∞–∑–º–µ—Ä: {len(file_content)} —Å–∏–º–≤–æ–ª–æ–≤\\n"
            f"üîó URI: {file_uri}"
        )
        
        await message.answer_document(file_doc, caption=caption)
        
    except Exception as e:
        logger.error(f"Error generating file: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")

@router.message(Command("diffzip"), F.reply_to_message)
async def diff_zip_archives(message: Message, session: AsyncSession = get_session()):
    """Compare ZIP archives and show differences."""
    try:
        st = await anext(session)
        proj = await get_active_project(st, message.from_user.id)
        if not proj:
            await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç: /project <name>")
            return
            
        if not message.reply_to_message or not message.reply_to_message.document:
            await message.answer("–ù—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –∫–æ–º–∞–Ω–¥–æ–π /diffzip –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å ZIP —Ñ–∞–π–ª–æ–º")
            return
            
        doc = message.reply_to_message.document
        if not doc or not doc.file_name or not doc.file_name.lower().endswith('.zip'):
            await message.answer("–ù—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –∫–æ–º–∞–Ω–¥–æ–π /diffzip –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å ZIP —Ñ–∞–π–ª–æ–º")
            return
            
        await message.answer("üîç –°—Ä–∞–≤–Ω–∏–≤–∞—é –∞—Ä—Ö–∏–≤—ã...")
        
        # Download new ZIP
        if not message.bot:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –±–æ—Ç—É")
            return
            
        file = await message.bot.get_file(doc.file_id)
        if not file.file_path:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
            return
            
        file_bytes_io = await message.bot.download_file(file.file_path)
        if not file_bytes_io:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª")
            return
            
        new_zip_data = file_bytes_io.read()
        
        # Validate new ZIP
        is_valid, error_msg = validate_zip_file(new_zip_data)
        if not is_valid:
            await message.answer(f"‚ùå {error_msg}")
            return
            
        # Find the latest ZIP/snapshot artifact
        artifacts = await list_artifacts(st, proj, kinds={'importzip', 'snapshot', 'blob'})
        latest_zip_artifact = None
        
        for artifact in artifacts:
            if artifact.uri and (artifact.tags and 'zip' in artifact.tags):
                latest_zip_artifact = artifact
                break
                
        if not latest_zip_artifact or not latest_zip_artifact.uri:
            await message.answer("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∞—Ä—Ö–∏–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            return
            
        # Download old ZIP from MinIO
        old_zip_key = latest_zip_artifact.uri.split('/')[-1]  # Extract key from URI
        old_zip_data = await load_file(old_zip_key)
        
        if not old_zip_data:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∞—Ä—Ö–∏–≤")
            return
            
        # Generate diff
        summary, diff_details = diff_archives(old_zip_data, new_zip_data)
        
        # Create full diff text
        full_diff = f"Comparison between {latest_zip_artifact.title} and {doc.file_name}\\n\\n"
        full_diff += summary + "\\n\\n"
        full_diff += "DETAILED DIFF:\\n" + "="*50 + "\\n"
        
        for file_path, file_diff in diff_details.items():
            full_diff += f"\\n\\nFILE: {file_path}\\n"
            full_diff += "-" * 40 + "\\n"
            full_diff += file_diff
            
        # Save diff to MinIO
        diff_filename = f"diff_{proj.name}_{doc.file_name}.txt"
        diff_uri = await save_file(diff_filename, full_diff.encode('utf-8'))
        
        # Gather context for analysis
        context_chunks = await gather_context(st, proj, user_id=message.from_user.id, max_chunks=20)
        
        # Get AI analysis
        analysis = await analyze_diff_context(summary, context_chunks)
        
        # Create diff artifact
        await create_import(
            st, proj,
            title=f"Diff: {latest_zip_artifact.title} vs {doc.file_name}",
            text=full_diff[:10000] + ("..." if len(full_diff) > 10000 else ""),  # Truncate for storage
            chunk_size=settings.chunk_size,
            overlap=settings.chunk_overlap,
            tags=['diff', 'comparison'],
            uri=diff_uri
        )
        
        await st.commit()
        
        # Send summary and analysis
        response = f"üìä <b>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–æ–≤</b>\\n\\n{summary}\\n\\n{analysis}\\n\\nüîó –ü–æ–ª–Ω—ã–π diff: {diff_uri}"
        
        # Split long messages
        if len(response) > 4000:
            await message.answer(f"üìä <b>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–æ–≤</b>\\n\\n{summary}")
            await message.answer(analysis)
            await message.answer(f"üîó –ü–æ–ª–Ω—ã–π diff: {diff_uri}")
        else:
            await message.answer(response)
            
        # Send diff file if not too large
        if len(full_diff.encode('utf-8')) < 10 * 1024 * 1024:  # 10MB limit
            diff_doc = BufferedInputFile(
                full_diff.encode('utf-8'),
                filename=diff_filename
            )
            await message.answer_document(
                diff_doc,
                caption=f"üìã –ü–æ–ª–Ω—ã–π diff –º–µ–∂–¥—É –∞—Ä—Ö–∏–≤–∞–º–∏"
            )
        
    except Exception as e:
        logger.error(f"Error comparing ZIP archives: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –∞—Ä—Ö–∏–≤–æ–≤: {str(e)}")