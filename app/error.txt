 ✔ project-memory-bot-bot                Built                                                                     0.0s
 ✔ Container project-memory-bot-minio-1  Healthy                                                                  11.1s
 ✔ Container project-memory-bot-db-1     Healthy                                                                  11.1s
 ✔ Container project-memory-bot-bot-1    Started                                                                  11.4s
bot-1  | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
bot-1  | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
bot-1  | INFO  [alembic.runtime.migration] Will assume transactional DDL.
bot-1  | INFO  [alembic.runtime.migration] Will assume transactional DDL.
bot-1  | INFO:__main__:Starting Telegram bot...
bot-1  | INFO:__main__:MinIO bucket ensured
bot-1  | INFO:__main__:Bot commands set successfully
bot-1  | INFO:__main__:Routers registered, starting polling...
bot-1  | INFO:aiogram.dispatcher:Start polling
bot-1  | INFO:aiogram.dispatcher:Run polling for bot @ProjectMemory_Bot id=8386572026 - 'ProjectMemoryBot'
bot-1  | INFO:aiogram.event:Update id=658402173 is handled. Duration 275 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402174 is handled. Duration 655 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402175 is handled. Duration 119 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402176 is handled. Duration 119 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402177 is handled. Duration 134 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402178 is not handled. Duration 17 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402179 is handled. Duration 117 ms by bot id=8386572026
bot-1  | DEBUG: active_proj: <app.models.Project object at 0x7f842ca77e50>
bot-1  | DEBUG: active_proj.id: 1, active_proj.name: lovender
bot-1  | DEBUG: proj: <app.models.Project object at 0x7f842ca77e50>
bot-1  | DEBUG: _render_panel - project_ids=[1], search_query='None', page=1
bot-1  | INFO:aiogram.event:Update id=658402180 is handled. Duration 1258 ms by bot id=8386572026
bot-1  | INFO:aiogram.event:Update id=658402181 is handled. Duration 123 ms by bot id=8386572026
bot-1  | INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
bot-1  | INFO:openai._base_client:Retrying request to /chat/completions in 0.403497 seconds
bot-1  | INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
bot-1  | INFO:openai._base_client:Retrying request to /chat/completions in 0.916000 seconds
bot-1  | INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
bot-1  | ERROR:app.llm:LLM error: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-a6ZpP0qup21B8P6cR45v8Nhl on tokens per min (TPM): Limit 30000, Requested 34934. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
bot-1  | Traceback (most recent call last):
bot-1  |   File "/app/app/llm.py", line 60, in ask_llm
bot-1  |     resp = await _client.chat.completions.create(
bot-1  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
bot-1  |   File "/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2583, in create
bot-1  |     return await self._post(
bot-1  |            ^^^^^^^^^^^^^^^^^
bot-1  |   File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
bot-1  |     return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
bot-1  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
bot-1  |   File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
bot-1  |     raise self._make_status_error_from_response(err.response) from None
bot-1  | openai.RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o in organization org-a6ZpP0qup21B8P6cR45v8Nhl on tokens per min (TPM): Limit 30000, Requested 34934. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
bot-1  | INFO:aiogram.event:Update id=658402182 is handled. Duration 4850 ms by bot id=8386572026