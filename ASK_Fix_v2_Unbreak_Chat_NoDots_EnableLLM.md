
# ASK Fix v2 ‚Äî Unbreak Chat, kill ‚Äú...‚Äù, enable LLM (with code)

> –¶–µ–ª—å: –≤–µ—Ä–Ω—É—Ç—å —Ä–∞–±–æ—á–∏–π —á–∞—Ç‚Äë–≥–µ–π—Ç, —É–±—Ä–∞—Ç—å ¬´‚Ä¶¬ª –Ω–∞–≤—Å–µ–≥–¥–∞ –∏ —Å–Ω–æ–≤–∞ –∑–≤–∞—Ç—å LLM. –ì–æ—Ç–æ–≤—ã–µ –≤—Å—Ç–∞–≤–∫–∏/–∑–∞–º–µ–Ω—ã –Ω–∏–∂–µ. –í—Å—Ç–∞–≤–ª—è–π –∏—Ö –≤ `app/handlers/ask.py` –∏ `app/services/llm.py`.

---

## 0) –ö–æ–Ω—Ñ–∏–≥ (–≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ)

```python
# app/config.py (–∏–ª–∏ –≥–¥–µ —É —Ç–µ–±—è –∫–æ–Ω—Ñ–∏–≥)
import os

LLM_DISABLED = os.getenv("LLM_DISABLED", "0") == "1"
ANSWER_BAR_WRAP = os.getenv("ANSWER_BAR_WRAP", "auto")  # auto|1|2
ANSWER_BAR_ICONS_ONLY = os.getenv("ANSWER_BAR_ICONS_ONLY", "1") == "1"
```
---

## 1) Router –ø–æ—Ä—è–¥–æ–∫ (–≤–∞–∂–Ω–æ, –∏–Ω–∞—á–µ –∫–æ–ª–ª–±—ç–∫–∏ –Ω–µ –ª–æ–≤—è—Ç—Å—è)

–í —Ñ–∞–π–ª–µ, –≥–¥–µ –ø–æ–¥–∫–ª—é—á–∞–µ—à—å —Ä–æ—É—Ç–µ—Ä—ã, **ASK –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—à–µ** –ª—é–±—ã—Ö ¬´–æ–±—â–∏—Ö¬ª/template‚Äë—Ä–æ—É—Ç–µ—Ä–æ–≤, –∞ `catch‚Äëall` ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–º:

```python
# app/bot.py (–ø—Ä–∏–º–µ—Ä)
from app.handlers.ask import ASK
# from app.handlers.templates import TEMPLATES  # –ø—Ä–∏–º–µ—Ä
# ...

dp.include_router(ASK)          # 1) ASK
# dp.include_router(TEMPLATES)  # 2) –¥—Ä—É–≥–∏–µ –ø–∞–Ω–µ–ª–∏/–º–æ–¥—É–ª–∏
# dp.include_router(CATCH_ALL)  # 3) catch-all –ø–æ—Å–ª–µ–¥–Ω–∏–º
```
---

## 2) Chat ON —á–µ—Ä–µ–∑ inline‚Äë–∫–Ω–æ–ø–∫—É (–±–µ–∑ ¬´—Ç–æ—á–µ–∫¬ª) ‚Äî **–∑–∞–º–µ–Ω–∞ —Ö–µ–Ω–¥–ª–µ—Ä–∞**

```python
# app/handlers/ask.py
from aiogram import F
from aiogram.types import CallbackQuery, ForceReply
import contextlib

@ASK.callback_query(F.data == "ask:chat:on")
async def ask_chat_on(cb: CallbackQuery, state: FSMContext):
    # –≤–∫–ª—é—á–∞–µ–º —Ñ–ª–∞–≥ –≤ —Å—Ç–µ–π—Ç–µ
    await state.update_data(chat_on=True)

    # —É–¥–∞–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É "–í–∫–ª—é—á–∏ —á–∞—Ç..." (–Ω–µ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ö–≤–æ—Å—Ç–æ–≤)
    with contextlib.suppress(Exception):
        await cb.message.delete()

    # –≤—ã–¥–∞—ë–º ForceReply "–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶" –∏ –∑–∞–ø–æ–º–∏–Ω–∞–µ–º id –ø—Ä–æ–º–ø—Ç–∞
    prompt = await cb.message.answer("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶", reply_markup=ForceReply(selective=True))
    await state.update_data(ask_prompt_msg_id=prompt.message_id, awaiting_ask_question=True)

    await cb.answer()  # —Ç–æ–ª—å–∫–æ –ø–æ–ø–∞–ø, –±–µ–∑ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
```
---

## 3) Chat ON/OFF —á–µ—Ä–µ–∑ reply‚Äë–∫–ª–∞–≤–∏–∞—Ç—É—Ä—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```python
# app/handlers/ask.py
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

def reply_kb(chat_on: bool) -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        keyboard=[[KeyboardButton(text="‚öôÔ∏è Actions"),
                   KeyboardButton(text=f"üí¨ Chat: {'ON' if chat_on else 'OFF'}"),
                   KeyboardButton(text="‚ùì ASK-WIZARD")]],
        resize_keyboard=True
    )

@ASK.message(F.text.regexp(r"^üí¨ Chat: (ON|OFF)$"))
async def toggle_chat_reply_button(msg: Message, state: FSMContext):
    data = await state.get_data()
    new_state = not bool(data.get("chat_on"))
    await state.update_data(chat_on=new_state)
    # –æ–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –æ–¥–Ω–∏–º –Ω–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏ –∑–∞–±—ã–≤–∞–µ–º —Å—Ç–∞—Ä–æ–µ
    m = await msg.answer(f"–ß–∞—Ç: {'–≤–∫–ª—é—á—ë–Ω' if new_state else '–≤—ã–∫–ª—é—á–µ–Ω'}", reply_markup=reply_kb(new_state))
    with contextlib.suppress(Exception):
        await msg.delete()
    # —ç—Ç–æ —Å–ª—É–∂–µ–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —á–µ—Ä–µ–∑ 3‚Äì5 —Å–µ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å TTL‚Äë—É–¥–∞–ª—è–ª–∫–∞)
```
---

## 4) –ü—Ä–∏—ë–º –≤–æ–ø—Ä–æ—Å–∞ ‚Äî **–Ω–µ —É–¥–∞–ª—è–µ–º** —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —É–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ ForceReply, –∑–æ–≤—ë–º LLM

```python
# app/handlers/ask.py
from aiogram.fsm.context import FSMContext
import time

@ASK.message()
async def ask_question_receiver(msg: Message, state: FSMContext):
    data = await state.get_data()
    if not data.get("awaiting_ask_question"):
        return

    # —É–±—Ä–∞—Ç—å ForceReply‚Äë–ø–æ–¥—Å–∫–∞–∑–∫—É
    with contextlib.suppress(Exception):
        pid = data.get("ask_prompt_msg_id")
        if pid:
            await msg.bot.delete_message(msg.chat.id, pid)

    # –≥–µ–π—Ç: —á–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ON
    if not data.get("chat_on"):
        await msg.answer("–í–∫–ª—é—á–∏ —á–∞—Ç –∫–Ω–æ–ø–∫–æ–π –≤–Ω–∏–∑—É –∏–ª–∏ —á–µ—Ä–µ–∑ ASK‚Äë–ø–∞–Ω–µ–ª—å.")
        return

    # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ (–æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø–æ—Ç–æ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º)
    prep = await msg.answer("–ì–æ—Ç–æ–≤–ª—é –æ—Ç–≤–µ—Ç‚Ä¶")

    # —Å–æ–±—Ä–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    selected_ids = data.get("selected_artifact_ids") or []
    if not selected_ids:
        await msg.bot.edit_message_text(chat_id=prep.chat.id, message_id=prep.message_id,
                                        text="–í—ã–±–µ—Ä–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ List.")
        await state.update_data(awaiting_ask_question=False)
        return

    # –í—ã–∑–æ–≤ LLM (—É–±–µ—Ä–∏ —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–≥–ª—É—à–µ—á–Ω—ã–π ¬´LLM –æ—Ç–∫–ª—é—á—ë–Ω¬ª)
    from app.config import LLM_DISABLED
    if LLM_DISABLED:
        answer_text = "LLM –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á—ë–Ω –∞–¥–º–∏–Ω–æ–º."
        run_id = f"stub-{int(time.time())}"
        used = list(selected_ids)
    else:
        answer_text, run_id, used = await run_llm_pipeline(
            user_id=msg.from_user.id,
            question=msg.text or "",
            source_ids=selected_ids
        )

    # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫–Ω–æ–ø–æ–∫
    await state.update_data(
        awaiting_ask_question=False,
        last_answer={
            "run_id": run_id,
            "question_msg_id": msg.message_id,
            "answer_msg_id": prep.message_id,
            "source_ids": used,
            "saved": False,
            "pinned": False,
        }
    )

    # –ø–æ–∫–∞–∑–∞—Ç—å –∏—Ç–æ–≥ –∏ –ø–∞–Ω–µ–ª—å (–∏–∫–æ–Ω–∫–∏‚Äë—Ç–æ–ª—å–∫–æ), –ø–∞–Ω–µ–ª–∏ –Ω–µ –∏—Å—á–µ–∑–∞—é—Ç –ø—Ä–∏ edit
    kb = answer_actions_kb(run_id, saved=False, pinned=False)
    await msg.bot.edit_message_text(
        chat_id=prep.chat.id,
        message_id=prep.message_id,
        text=answer_text + "\n\n" + "üìö Sources: " + ", ".join(f"id{sid}" for sid in used),
        reply_markup=kb
    )
```
---

## 5) –£–±–∏—Ç—å ¬´‚Ä¶¬ª –≤–æ –≤—Å–µ—Ö –º–µ—Å—Ç–∞—Ö

**–ò—â–∏ –∏ —É–¥–∞–ª—è–π** —Ç–∞–∫–∏–µ –≤—ã–∑–æ–≤—ã (–æ–Ω–∏ –∂–µ —Å–ø–∞–º—è—Ç —Ç–æ—á–∫–∞–º–∏):
- `await message.answer(".")`
- `await cb.message.answer(".")`
- –ª—é–±–æ–π helper `send_status("...")` / `send_dots()`

–í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ:
- –ò—Å–ø–æ–ª—å–∑—É–π `await cb.answer("–ì–æ—Ç–æ–≤–æ")` –¥–ª—è –∫–æ—Ä–æ—Ç–∫–æ–π –ø–æ–¥—Å–∫–∞–∑–∫–∏;  
- –ò–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (`edit_message_text / edit_reply_markup`).

**–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞:** –ø–æ –ø—Ä–æ–µ–∫—Ç—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å grep:  
`rg -n 'answer\("\."\)' app` –∏ `rg -n '"\."' app`

---

## 6) Answer‚Äë–±–∞—Ä ‚Äî –Ω–µ –ø—Ä–æ–ø–∞–¥–∞–µ—Ç

–õ—é–±–æ–π `edit_message_text` –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ** –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å `reply_markup=answer_actions_kb(...)`.  
–ï—Å–ª–∏ —ç—Ç–æ–≥–æ –Ω–µ —Å–¥–µ–ª–∞—Ç—å —Ö–æ—Ç—è –±—ã —Ä–∞–∑ ‚Äî Telegram —Å–Ω–∏–º–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É, –∏ ¬´–∫–Ω–æ–ø–∫–∏ –ø—Ä–æ–ø–∞–ª–∏¬ª.

```python
def answer_actions_kb(run_id: str, *, saved: bool, pinned: bool) -> InlineKeyboardMarkup:
    kb = InlineKeyboardBuilder()
    kb.button(text=("‚úÖ" if saved else "üíæ"), callback_data=f"ask:answer:save:{run_id}")
    kb.button(text=("üìç" if pinned else "üìå"), callback_data=f"ask:answer:pin:{run_id}")
    kb.button(text="üßæ", callback_data=f"ask:answer:summary:{run_id}")
    kb.button(text="üîÅ", callback_data=f"ask:answer:refine:{run_id}")
    kb.button(text="üìö", callback_data=f"ask:answer:sources:{run_id}")
    kb.button(text="üóë", callback_data=f"ask:answer:delete:{run_id}")
    kb.adjust(6)
    return kb.as_markup()
```
---

## 7) LLM payload –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (OpenAI 400 fix)

–ï—Å–ª–∏ –ª–æ–≤–∏–ª `Unsupported value: 'temperature'` –∏–ª–∏ ¬´–Ω–µ —Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä max_tokens¬ª, –¥–æ–±–∞–≤—å —Ö–µ–ª–ø–µ—Ä:

```python
# app/services/llm.py
TEMPERATURE_SUPPORTED = ("gpt-3.5-turbo", "gpt-4", "gpt-4-turbo", "gpt-4o")
REASONING_FAMILY = ("o1", "o3", "o4", "o5", "gpt-5", "gpt-5-thinking")

def _model_caps(model: str) -> dict:
    m = model.lower()
    caps = {"use_temperature": False, "tokens_param": "max_tokens"}
    if any(m.startswith(x) for x in TEMPERATURE_SUPPORTED):
        caps["use_temperature"] = True
    if any(m.startswith(x) for x in REASONING_FAMILY):
        caps["use_temperature"] = False
        caps["tokens_param"] = "max_completion_tokens"
    return caps

def build_openai_payload(model: str, messages: list, *, temperature: float|None, max_tokens: int|None):
    caps = _model_caps(model)
    payload = {"model": model, "messages": messages}
    if max_tokens:
        payload[caps["tokens_param"]] = max_tokens
    if caps["use_temperature"] and temperature is not None and temperature != 1:
        payload["temperature"] = float(temperature)
    return payload
```
–ò—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.

---

## 8) Acceptance ‚Äî –±—ã—Å—Ç—Ä–æ –ø—Ä–æ–≥–Ω–∞—Ç—å

- –ù–∞–∂–∏–º–∞—é inline ¬´–í–∫–ª—é—á–∏—Ç—å —á–∞—Ç¬ª ‚Üí –ø–æ–¥—Å–∫–∞–∑–∫–∞ –∏—Å—á–µ–∑–∞–µ—Ç, –ø–æ—è–≤–ª—è–µ—Ç—Å—è ForceReply ¬´–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶¬ª (–±–µ–∑ ¬´‚Ä¶¬ª).
- –ü–∏—à—É –≤–æ–ø—Ä–æ—Å ‚Üí ForceReply —É–¥–∞–ª—ë–Ω, –º–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ **–æ—Å—Ç–∞–ª–æ—Å—å**; ¬´–ì–æ—Ç–æ–≤–ª—é –æ—Ç–≤–µ—Ç‚Ä¶¬ª ‚Üí –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ + –ø–∞–Ω–µ–ª—å –∏–∫–æ–Ω–æ–∫; `üìö` ‚Äî –æ–≤–µ—Ä–ª–µ–π, `‚Ü©Ô∏è Back` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–Ω–µ–ª—å.
- –¢—É–º–±–ª–µ—Ä—ã/–ø–∞–≥–∏–Ω–∞—Ü–∏—è/–ø–æ–∏—Å–∫ ‚Äî –Ω–µ —Å–æ–∑–¥–∞—é—Ç –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π; –º–∞–∫—Å–∏–º—É–º ‚Äî –≤—Å–ø–ª—ã–≤–∞—à–∫–∞.
- LLM —Ä–µ–∞–ª—å–Ω–æ –∑–æ–≤—ë—Ç—Å—è (–µ—Å–ª–∏ `LLM_DISABLED=0`) ‚Äî –Ω–µ—Ç –∑–∞–≥–ª—É—à–∫–∏ ¬´TEST: LLM –æ—Ç–∫–ª—é—á—ë–Ω`.
